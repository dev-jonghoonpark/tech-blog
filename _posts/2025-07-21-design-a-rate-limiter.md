https://www.youtube.com/watch?v=VzW41m4USGs
https://lilys.ai/digest/5082865/4473210

7: Design a Rate Limiter | Systems Design Interview Questions With Ex-Google SWE

📌 시스템 설계에서 Rate Limiter를 설계하는 방법은 무엇인가요?
Rate Limiter는 악의적이거나 부주의한 사용자가 너무 많은 요청을 보내는 것을 막아 서비스에 추가적인 부하를 주거나 서비스를 중단시키는 것을 방지하며, 최소한의 지연 시간을 도입하고 다양한 Rate Limiting 기술을 지원하도록 설계해야 합니다. [15]

💡 Rate Limiter를 설계할 때 고려해야 할 주요 사항은 무엇인가요?
Rate Limiting 대상: 사용자 ID와 IP 주소를 혼합하여 사용하며, 비인증 엔드포인트에는 IP 주소를, 로그인 후에는 사용자 ID를 사용하는 하이브리드 접근 방식이 가장 효과적입니다. [49]

Rate Limiter 위치: 애플리케이션 서버를 대규모 네트워크 트래픽으로부터 보호하고 독립적으로 확장할 수 있는 전용 분산 Rate Limiter 계층으로 구현하는 것이 좋습니다. [79]

데이터베이스 선택: 읽기 및 쓰기 속도를 최적화하기 위해 Redis와 같은 인메모리 데이터베이스를 사용하는 것이 좋습니다. [104]

복제 방식: Rate Limiter의 내결함성을 위해 단일 리더 복제 방식을 사용하여 데이터 일관성을 유지하는 것이 중요합니다. [121]

Rate Limiting 알고리즘: 고정 윈도우(Fixed Window)와 슬라이딩 윈도우(Sliding Window) 알고리즘을 고려하며, 슬라이딩 윈도우는 더 정확한 제어를 제공합니다. [127]

동시성 고려사항: 카운터 증가 및 연결 리스트 수정 시 발생할 수 있는 경쟁 조건을 방지하기 위해 잠금(locking) 또는 단일 스레드 방식을 사용해야 합니다. [172]

이 튜토리얼은 전직 Google 소프트웨어 엔지니어가 시스템 설계 인터뷰에서 자주 나오는 질문인 'Rate Limiter 설계'에 대해 설명합니다. Rate Limiter는 악의적이거나 부주의한 사용자가 과도한 요청을 보내 서비스에 과부하를 주는 것을 방지하는 데 사용됩니다. 이 튜토리얼에서는 Rate Limiter의 요구 사항, 용량 추정, Rate Limiting을 수행할 대상(사용자 ID 또는 IP 주소), Rate Limiting 인터페이스, 시스템 내 Rate Limiter의 위치, 데이터베이스 선택, 복제 선택, 고정 창 Rate Limiting 및 슬라이딩 창 Rate Limiting과 같은 다양한 알고리즘에 대해 설명합니다. 이 튜토리얼은 서비스의 안정성과 사용자 경험을 보장하기 위해 Rate Limiter를 설계하는 방법에 대한 포괄적인 가이드를 제공합니다.

# 1. 🔧 레이트 리미터의 역할과 필요성

레이트 리미터는 서버가 특정 사용자 또는 클라이언트의 요청 횟수에 제한을 두기 위해 사용된다. [6]

예를 들어, 유튜브에서는 사용자가 비정상적으로 많은 조회수를 생성하는 것을 방지하기 위해 요청 빈도를 제한한다. [8]

제한이 초과될 경우 서버는 요청을 차단하거나 일정 시간 후 다시 요청할 수 있도록 응답한다. [12]

# 2. 🛡️ 리밋터의 기본 목적과 필요성

사용자와 악의적 또는 부주의한 사용자 모두의 과도한 요청을 방지하여 서비스 과부하를 막아야 한다 [13]

요청이 너무 많아지면 서버의 부하가 증가하고, 서비스 제공이 저하될 수 있기 때문에 이를 방지하는 것이 목표다 [14]

최소한의 지연 시간으로 모든 요청을 처리해야 하며, 지연 증가 시 사용자 경험에 악영향이 생길 수 있다 [18]

다양한 rate limiting 기법을 지원하며, 대표적인 알고리즘보다 아키텍처 설계를 중점적으로 고려하는 것이 바람직하다 [21]

🔢 용량 추정과 시스템 규모

10억 명의 사용자와 20개 서비스(엔드포인트)에 대한 수요를 가정한다 [28]

각 사용자는 8바이트의 사용자 ID와 4바이트의 요청 카운터를 유지하며, 실제로는 더 많은 메타데이터가 필요할 수 있다 [31]

최소 요청 데이터 크기를 계산하면 약 12바이트로, 이를 10억 사용자와 20개 서비스에 곱하면 약 240GB의 저장 공간이 요구된다 [34]

이 데이터는 인메모리 저장에 부적합하며, 256GB 서버를 사용하더라도 저장에 한계가 있어 서버를 파티셔닝하는 방식이 필요할 것으로 예상된다 [35]

# 3. 🚀 사용자별, IP별, 엔드포인트별 레이트 제한 방법

요청 대상은 사용자 ID, IP 주소, 또는 요청 엔드포인트 중 하나로 선택하며, 사용자 인증 유무에 따라 달라진다 [39]

사용자 ID는 요청 추적이 쉽고, 악의적 사용자 차단에 유효하지만 계정을 여러 개 만들 경우 한계가 있다 [41]

IP 주소는 로그인 여부와 무관하게 추적 가능하며, 같은 네트워크 내 다중 계정을 방지하는 데 유리하지만 오작동 가능성도 있다 [44]

하이브리드 방식으로, 비인증 요청은 IP 주소를, 인증된 사용자 요청은 사용자 ID를 활용하는 전략이 추천된다 [48]

🧩 Rate Limiting 인터페이스 설계

요청은 사용자 ID 또는 IP, 서비스 이름, 요청 시간 등을 입력값으로 받으며, 요청 제한 여부를 Boolean으로 반환하는 함수로 설계한다 [49]

서비스별 또는 사용자별로 별도 제한이 필요하며, 시간 간격에 기반한 시간대응 방식이 주로 사용된다 [55]

⚙️ 시스템 내 위치에 따른 Rate Limiter 구조

로드 밸런서와 별개로 각 서비스 내부 또는 전담 분산 레이트 제한 층 배치 가능하며, 각각의 장단점이 존재한다 [56]

🔧 로컬 레이트 제한의 장단점

장점: 네트워크 요청이 없고, 요청 데이터를 서비스 내부에 저장하므로 빠른 응답 가능 [64]

단점: 대량 요청 시 네트워크 대역폭 사용 증대, 확장성 부족, 서버 장애 시 정보 유실 가능성이 있다 [67]

🌍 분산 레이트 제한의 장단점

장점: 트래픽을 차단하여 서버에 도달하는 요청 수를 제한하며, 독립적 확장과 관리를 용이하게 한다 [78]

단점: 네트워크 요청이 추가되어 지연이 발생하며, 구현 복잡성과 네트워크 부하가 증가한다 [79]

# 4. ⚡ 캐시를 활용한 부하 분산 및 요청 제한 방법

부하 분산기에서 일부 인기 사용자 요청에 대해 쓰기-회수 캐시를 적용하여, 네트워크 요청을 줄이는 방안을 제시한다. [87]

요청 수를 기준으로 일정 시간 내에 특정 사용자 요청이 일정 수준(예: 5회)일 경우 캐시에 저장하여, 이후 요청 시 바로 참고할 수 있다. [89]

이 방법으로, 특정 스팸 유저는 실제 요청 제한 시스템에 도달하지 않고 부하 분산기 단계에서 차단 가능하다. [94]

모든 캐시 내용이 단일 부하 분산기와 연동되는 경우에 효과적이며, 다중 부하 분산기 환경에서는 요청 분할 방안을 고려해야 한다. [96]

이 접근법은 부하 분산기를 이용한 부분적 요청 제한의 유용성을 보여준다. [87]

💾 인메모리 데이터베이스를 활용한 속도 향상 방안

요청 속도를 위해 디스크 접근 없이 모든 데이터를 인메모리, Redis 또는 Memcached에 저장하는 방식을 제안한다. [102]

Redis를 추천하는 이유는 내장 자료구조와 복제(Replication) 기능이 쉽게 구현 가능하기 때문이다. [104]

인메모리 데이터베이스 사용은 데이터 액세스를 매우 빠르게 만들어, 시스템의 병목 현상을 최소화한다. [102]

🔄 복제 방식 선택과 장애 극복 방안

높은 가용성을 위해 단일 리더(leader) 구조를 선호하며, 다중 리더 또는 리더리스 복제는 데이터 불일치를 야기할 수 있어 적합하지 않다고 본다. [110]

멀티리더 환경에서는 동기화 지연, 즉 anti-entropy 과정이 필요하며, 이로 인한 일시적 데이터 불일치 문제를 해결하는 기술이 필요하다. [116]

CRDT(합집합 자료구조)를 이용해 분산된 카운트 값을 병합하는 방법도 있지만, 단일 리더 구조가 더 정확하다고 보는 견해를 제시한다. [118]

단일 마스터 노드와 팔로워 구조를 통해, 쓰기 동기화와 읽기 일관성을 보장하는 것이 가장 안정적이라고 설명한다. [121]

읽기 요청은 여전히 팔로워에 분산 가능하지만, 성능 저하로 인해 적절한 파티션 전략이 필요함을 언급한다. [122]

# 5. ⚡ 고정 윈도우 기반 레이트 제한

고정 윈도우 방식은 일정 시간 간격(예: 1분)마다 요청 횟수 제한이 초기화된다고 설명한다 [128]

요청은 서비스명, 사용자 ID, 요청 시간으로 구성된 맵에 저장되며, 요청 시마다 현재 윈도우와 요청 수를 갱신하는 방식이다 [132]

요청 시간이 현재 윈도우와 같으면 요청 수를 증가시키고, 그렇지 않으면 윈도우를 갱신한다 [142]

요청 수가 제한값(예: 2)을 초과하면 해당 요청을 차단한다 [138]

간단하고 직관적이지만, 윈도우가 변경될 때마다 리셋이 필요하다 [130]

🌊 슬라이딩 윈도우 기반 레이트 제한

슬라이딩 윈도우는 요청이 일정 시간(예: 1분) 내에 특정 횟수(예: 2회)를 넘지 않도록 제한한다 [149]

요청은 연결 리스트(링크드 리스트)에 저장하며, 요청 시 오래된 요청부터 제거하는 방식이다 [153]

요청 시간 기준으로 컷오프 시간(현재 요청 시간 - 윈도우 크기)을 계산하고, 리스트의 노드 중 이보다 오래된 요청들은 삭제한다 [165]

요청이 유효하면 리스트에 추가하고, 제한을 초과하면 차단한다 [167]

요청 시마다 오래된 요청 제거와 새 요청 추가 과정을 반복한다 [164]

이 방법은 매우 최근 요청만을 고려하기 때문에, 요청 간격이 일정 이상 차이 나면 유효한 요청으로 간주한다 [152]

🛠️ 동시성 및 스레드 안전 고려 사항

다중 스레드 환경에서는 카운터 증감이나 링크드 리스트 수정 시 잠금(lock) 또는 원자적 연산이 필요하다 [172]

요청 처리 과정에서 경쟁 조건 발생 가능성이 있으므로, 현대 언어의 동시성 지원 기능을 활용하는 것이 바람직하다 [176]

락ing을 통한 안전한 데이터 구조 접근이 중요하며, 그렇지 않으면 데이터 손상이나 예측 불가능한 동작이 발생할 수 있다 [179]

🎯 전체 설계 구조와 구현 방안

로드 밸런서 내에 레이트 리미터 캐시를 두어 요청을 먼저 차단하고, 백엔드 서버의 부하를 줄인다 [185]

요청이 제한을 넘지 않으면 백엔드 서비스로 전달되고, 넘는 경우 차단한다 [189]

설계는 간단하면서도 효율적인 요청 제한 시스템을 목표로 한다 [190]

이러한 방식은 분산 시스템 환경에서도 요청 제한을 효과적으로 적용할 수 있도록 설계된다

## 5.1. 고정 윈도우(예: 1분 단위) 기반 속도 제한

일정 시간 단위(예: 1분)가 시작할 때마다 요청 수가 초기화되며, 이때 정해진 요청 허용량(예: 2건)을 초과하는 요청은 차단된다 [124]

요청이 들어올 때마다 서비스 이름과 사용자 ID를 키로 하는 맵에서 현재 요청 시점과 요청 수를 저장하는 구조를 사용한다 [131]

요청이 동일한 시간(분) 내에 들어오면 요청 수를 증가시키고, 시간이 바뀌면 초기화된 새 시간과 요청 수로 갱신한다 [133]

요청 수가 정해진 한도(예: 2개)를 넘으면 해당 요청을 차단한다 [136]

이 방식은 요청이 시작하는 시점마다 요청수를 다시 세며, 한도를 넘는 요청을 비정상으로 처리한다 [137]

🔀 슬라이딩 윈도우(유연한 시간 범위) 기반 속도 제한

슬라이딩 윈도우 방식은 일정한 시간 구간에 요청이 집중될 경우, 보다 정밀하게 요청 수를 제한한다

이 방법은 요청 시간별로 요청 기록을 저장하고, 일정 시간 범위 내 요청 수를 계산하여 제한한다

하지만 본 영상은 주로 고정 윈도우 방식을 설명하며, 슬라이딩 윈도우는 별도 참고용으로 언급된다 [126]

## 5.2. 슬라이딩 윈도우 기반 레이트 리미팅 원리

슬라이딩 윈도우는 일정 시간 내 요청 수를 제한하는 방식으로, 예를 들어 1분 내 요청이 2회를 초과하면 제한하는 방식이 적용된다 [148].

요청이 들어올 때마다, 먼저 저장된 이전 요청들을 시간 범위 밖으로 삭제하여 최신 요청만 유지한다 [157].

요청의 유효성은 요청 시간이 윈도우 내에 포함되어 있고, 기존 요청 수가 제한을 초과하지 않는 경우에 결정된다 [149].

요청이 제한을 초과하면 해당 요청은 무시하고, 제한 내에서는 요청을 링크드 리스트에 추가한다 [158].

요청을 처리하는 과정은 요청 시간 기준으로 이전 요청을 제거 후, 새 요청을 리스트에 추가하는 두 단계로 이루어진다 [164].

## 5.3. 병렬 처리와 경쟁 조건 고려의 필요성

경합 상태(race condition)를 방지하기 위해 동시성(concurrency) 또는 스레딩(threading) 고려가 필요하다는 점을 언급한다 [171].

고정 윈도우 알고리즘에서는 카운터 읽기와 증분이 원자적(atomic)으로 이루어져야 하며, 그렇지 않으면 로스트 업데이트(중복 증분) 문제가 발생할 수 있다 [172].

로스트 업데이트를 막기 위해 잠금(lock)을 사용하거나 단일 스레드로 처리하는 방법이 있으며, 후자는 부득이하게 성능 저하를 유발한다라는 설명이다 [172].

슬라이딩 윈도우 구현 시, 링크드 리스트의 병행 수정으로 인한 예외 발생 가능성을 고려해야 한다는 점을 지적한다 [173].

두 개 이상의 스레드가 동시에 리스트의 헤드를 수정하려 할 경우, 예상치 못한 삭제 또는 수정 동작이 발생할 수 있다는 문제를 지적한다 [175].

현대 프로그래밍 언어에는 병렬 링크드 리스트 구현체가 존재하며, 이들을 사용하는 것이 권장된다는 점을 언급한다 [177].

리스트 삭제 시에도 동시에 두 스레드가 같은 요소를 삭제하는 일이 발생할 수 있으며, 이는 정의된 행동이 불명확해질 수 있다다 [178].

단일 스레드 처리 또는 락을 사용하는 방식 외에는 명확한 해결책이 부재하며, 데이터 구조의 병행 접근 문제는 필연적임을 나타낸다 [179].

## 5.4. ️ 레이트 리미터 설계의 기본 구조와 역할

레이트 리미터는 부하 분산기와 요청 캐시를 통해 요청 속도를 제어하는 역할을 한다. [185]

부하 분산기 내부에는 요청을 저장하는 캐시가 있어서, 특정 악의적 사용자의 요청을 사전에 차단할 수 있다. [186]

레이트 리미터는 단일 리더 복제 방식의 파티셔닝 구조를 사용하며, 이는 백업과 장애 복구에 유리하다고 추정된다. [187]

요청이 들어오면 먼저 레이트 리미터 서비스를 통해 제한 여부를 검사한 후, 제한이 없다면 백엔드 서비스로 요청을 전달한다. [188]

설계는 간단하며, 핵심 역할은 요청 속도 제한과 이에 따른 요청 분배 또는 차단이다. [184]
